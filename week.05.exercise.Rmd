---
title: "Week 05 in Statistical machine learning in bioinformatics"
author: "Thomas Bataillon"
date: "25/02/2021"
output:
  html_document:
        theme: readable
editor_options: 
  chunk_output_type: console
---

  git config --global user.email "you@example.com"
  git config --global user.name "Your Name"

---

## ALS dataset 

MULTIPLE LINEAR REGRESSION

Load Libraries
```{r}
# install.packages(c('tibble', 'dplyr', 'tidyr'))
library(tibble)
library(dplyr)
library(tidyr)
library(tidyverse)
library(car)

```


Loading the data
```{r}
als <- read_rds("datasets/ALS_data_regression/ALS_progression_rate.1822x370.rds")

als_train <- als %>% 
  filter(!is.na(dFRS))

als_predict <- als %>% 
  filter(is.na(dFRS))


head(als_train)
head(als_predict)

sum(is.na(als_train))

```

Find the best predictors:
https://stackoverflow.com/questions/18275639/remove-highly-correlated-variables

```{r}
correlation_matrix<-cor(als_train)
```


>Q Use multiple linear regression for making prediction on the ALS rsponse variable 

```{r}

#Make model with ALL predictors (We should check which are more important)

mlg <- lm(dFRS~.,data=als_train)
summary(mlg$coefficients)
summary(mlg)

#We observe 9 predictors which give NA, we will remove them manually from our model

mlg <- lm(dFRS~. -Site.of.Onset.Onset..Limb.and.Bulbar -mean.height -sd.height -no.height.data -no.resp.rate.data -no.bp.diastolic.data -no.slope.fvc.liters.data -first.slope.height.date -num.slope.bp.systolic.visits,data=als_train)


#If we run vif we can see which ones we should remove. 
all_vifs<-car::vif(mlg)
signif_all <- names(all_vifs)

# Remove vars with VIF> 4 and re-build model until none of VIFs don't exceed 4.
while(any(all_vifs > 4)){
  var_with_max_vif <- names(which(all_vifs == max(all_vifs)))  # get the var with max vif
  signif_all <- signif_all[!(signif_all) %in% var_with_max_vif]  # remove
  myForm <- as.formula(paste("dFRS ~ ", paste (signif_all, collapse=" + "), sep=""))  # new formula
  selectedMod <- lm(myForm, data=als_train)  # re-build model with new formula
  all_vifs <- car::vif(selectedMod)
}
summary(selectedMod)
car::vif(selectedMod)

#Predict dFRS on our predict dataframe
glm_als_predict<-als_predict
glm_als_predict$dFRS_Predicted = predict.glm(mlg, glm_als_predict, type = "response")

#Plot the fit using Onset.Delta since it is continuous 
ggplot(glm_als_predict, aes(x=Onset.Delta, y=dFRS_Predicted)) +
  geom_point() +
  geom_smooth(method = "glm", se = FALSE) + 
  NULL
```



>Q use cross validation to examine how accurate are the predictions you can make

```{r}
# Function for calculating the 10-fold CV error
cross_validation <- function(dataset, k=10){
  
  cvfolds <- cut(seq_len(nrow(dataset)), breaks = k, labels = FALSE)  # Generate breaks
  cvfolds <- sample(cvfolds)                                      # Randomize breaks

  observed  <- dataset$dFRS                                       # Get observed values
  predicted <- rep(NA, nrow(dataset))                             # Empty vector for predicted values
  
  for (i in 1:k){                                                 # For each fold
    rows      <- which(cvfolds==i)                                # Get values belonging to that fold
    testdata  <- dataset[rows,]                                   # Get test values
    traindata <- dataset[-rows,]                                  # Get training values
    fit       <- lm(dFRS~., data=traindata)                       # Fit the model with training data
    tmp       <- predict(fit,newdata = testdata)                  # Predict on test data
    predicted[rows] <- tmp                                        # Add predictions to vector
  }
  
  rmse_cv <- sqrt(mean((observed-predicted)^2))        # Calculate CV RMSE

    fit        <- lm(dFRS~., data=dataset)                          # Fit the model with all the dataset
  observed   <- dataset$dFRS                                      # Get observed values
  predicted  <- predict(fit,newdata = dataset)                    # Get predicted values
  rmse_train <- sqrt(mean((observed-predicted)^2))     # Calculate training RMSE
  
  return(c(rmse_cv, rmse_train))                                  # Return CV and training RMSEs
}

pd <- tibble(run=1:5)                                             # Empty tibble for five different runs

for (i in pd$run) {                                               # For each of the runs
  set.seed(i)
  r <- cross_validation(als_train, 10)                             # Run the CV analysis
  pd$rmse_cv[i] <- r[1]                                           # Save the CV RMSE
  pd$rmse_train <- r[2]                                           # Save the training RMSE
  cat("Run", i, "\n")                                             # Print status
  flush.console()
}

knitr::kable(pd)
```


>Q Upload yourbest predictions as a TEAM using a rds format 



## TCGA dataset

>Q Apply classication methods to the TCGA datset for making prediction on  samples

You can use any method we have covered so far (i.e. logistic regression , LDA QDA or even KNN) and use any predictors from the TCGA dataset.


CANCER-> Logistic
TISSUE-> LDA or QDA

>Q use cross validation to examine how accurate are the predictions you can make 

>Q Apply QDA to the TCGA datset for making prediction on tissues samples

>Q submit your  best predictions as a TEAM using a rds format 
