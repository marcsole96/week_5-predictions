---
title: "Week 05 in Statistical machine learning in bioinformatics"
author: "Thomas Bataillon"
date: "25/02/2021"
output:
  html_document:
        theme: readable
editor_options: 
  chunk_output_type: console
---

  git config --global user.email "you@example.com"
  git config --global user.name "Your Name"

---


## ALS dataset 

MULTIPLE LINEAR REGRESSION

Load Libraries
```{r}
# install.packages(c('tibble', 'dplyr', 'tidyr'))
library(tibble)
library(dplyr)
library(tidyr)
library(tidyverse)
library(car)

```


Loading the data
```{r}
als <- read_rds("datasets/ALS_data_regression/ALS_progression_rate.1822x370.rds")

als_train <- als %>% 
  filter(!is.na(dFRS))

als_predict <- als %>% 
  filter(is.na(dFRS))


head(als_train)
head(als_predict)

sum(is.na(als_train))

```


We can make a correlation matrix to take a peek at how much correlation between the predictors we observe
```{r}
correlation_matrix<-cor(als_train)
```


>Q Use multiple linear regression for making prediction on the ALS rsponse variable 

```{r}

#Make model with ALL predictors (We should check which are more important)

mlg <- lm(dFRS~.,data=als_train)
summary(mlg$coefficients)
summary(mlg)

#We observe 9 predictors which give NA, we will remove them manually from our model

mlg <- lm(dFRS~. -Site.of.Onset.Onset..Limb.and.Bulbar -mean.height -sd.height -no.height.data -no.resp.rate.data -no.bp.diastolic.data -no.slope.fvc.liters.data -first.slope.height.date -num.slope.bp.systolic.visits,data=als_train)


#If we run vif we can see which ones we should remove. 
all_vifs<-car::vif(mlg)
signif_all <- names(all_vifs)

# Remove vars with VIF> 4 and re-build model until none of VIFs don't exceed 4.
while(any(all_vifs > 4)){
  var_with_max_vif <- names(which(all_vifs == max(all_vifs)))  # get the var with max vif
  signif_all <- signif_all[!(signif_all) %in% var_with_max_vif]  # remove
  myForm <- as.formula(paste("dFRS ~ ", paste (signif_all, collapse=" + "), sep=""))  # new formula
  mlg <- lm(myForm, data=als_train)  # re-build model with new formula
  all_vifs <- car::vif(mlg)
}
summary(mlg)
car::vif(mlg)

#Predict dFRS on our predict dataframe
glm_als_predict<-als_predict
glm_als_predict$response = predict.glm(mlg, glm_als_predict, type = "response")

#Plot the fit using Onset.Delta since it is continuous 
ggplot(glm_als_predict, aes(x=Onset.Delta, y=dFRS_Predicted)) +
  geom_point() +
  geom_smooth(method = "glm", se = FALSE) + 
  NULL



```



>Q use cross validation to examine how accurate are the predictions you can make

```{r}
# Function for calculating the 10-fold CV error
cross_validation <- function(dataset, k=10){
  
  cvfolds <- cut(seq_len(nrow(dataset)), breaks = k, labels = FALSE)  # Generate breaks
  cvfolds <- sample(cvfolds)                                      # Randomize breaks

  observed  <- dataset$dFRS                                       # Get observed values
  predicted <- rep(NA, nrow(dataset))                             # Empty vector for predicted values
  
  for (i in 1:k){                                                 # For each fold
    rows      <- which(cvfolds==i)                                # Get values belonging to that fold
    testdata  <- dataset[rows,]                                   # Get test values
    traindata <- dataset[-rows,]                                  # Get training values
    fit       <- lm(myForm, data=traindata)                       # Fit the model with training data
    tmp       <- predict(fit,newdata = testdata)                  # Predict on test data
    predicted[rows] <- tmp                                        # Add predictions to vector
  }
  
  rmse_cv <- sqrt(mean((observed-predicted)^2))        # Calculate CV RMSE

    fit        <- lm(myForm, data=dataset)                          # Fit the model with all the dataset
  observed   <- dataset$dFRS                                      # Get observed values
  predicted  <- predict(fit,newdata = dataset)                    # Get predicted values
  rmse_train <- sqrt(mean((observed-predicted)^2))     # Calculate training RMSE
  
  return(c(rmse_cv, rmse_train))                                  # Return CV and training RMSEs
}

pd <- tibble(run=1:5)                                             # Empty tibble for five different runs

for (i in pd$run) {                                               # For each of the runs
  set.seed(i)
  r <- cross_validation(als_train, 10)                             # Run the CV analysis
  pd$rmse_cv[i] <- r[1]                                           # Save the CV RMSE
  pd$rmse_train <- r[2]                                           # Save the training RMSE
  cat("Run", i, "\n")                                             # Print status
  flush.console()
}

knitr::kable(pd)
```



```{r}
# Always make the same split
set.seed(0)

# We use 80% for training and 20% for evaluation
trainfold <- als_train %>% sample_frac(size=0.80)
testfold  <- setdiff(als_train, trainfold)

# We fit our model to the training fold
fit <-  lm(formula  = myForm, data = trainfold)

# We predict on the test fold
predicted <- predict(fit, newdata = testfold)

submission <- tibble(predicted)

# We compare with the observed values and calculate RMSE
observed  <- testfold$dFRS
mse       <- mean((observed-predicted)^2)
(rmse     <- sqrt(mse))

test_rmse <- rmse
```


# Submitting your answer

The following code will give us

* your chosen team name
* the name of the people on the team
* your estimated RMSE (from train/test or CV or similar)
* your predictions

Please edit the values below .

The filename of the output will be automated als_progression.TEAMNAME.rds

Please - do not use space or funny letters in your team name.

```{r}

team_name        <- "Team Bulbasaur"
team_people      <- c("Max Gubert", "Rikke Jensen", "Marc SolÃ©")
team_error_rate  <- test_rmse
team_predictions <- submission

#
# Always run this code
# If it fails you have done something wrong!
#
# Extract the columns needed
team_predictions <- team_predictions %>% select(predicted)

# Save all the stuff in one object
write_rds(x = list(team_name, team_people, team_error_rate, team_predictions), 
          path = paste("als_progression.", team_name, ".rds", sep=""))

```

# Checking format of all saved objects

```{r}

files   <- Sys.glob("als_progression.*.rds")
results <- tibble(filename = files, team_name=NA, team_people=NA, team_rmse=NA,n=NA, mean=NA)

for (i in 1:nrow(results)) {
  x <- read_rds(path = as.character(results$filename[i]))
  results$team_name[i]        <- x[[1]]
  results$team_people[i]      <- paste(x[[2]], collapse=",", sep=" ")
  results$team_rmse[i]        <- x[[3]]
  y                           <- x[[4]]
  results$n                   <- nrow(y)
  results$mean                <- mean(y$predicted, na.rm = T)
}

rm(x,y)

results %>% select(-filename)

```

# Upload your rds file!













>Q Upload yourbest predictions as a TEAM using a rds format 



## TCGA dataset

>Q Apply classication methods to the TCGA datset for making prediction on  samples

You can use any method we have covered so far (i.e. logistic regression , LDA QDA or even KNN) and use any predictors from the TCGA dataset.


CANCER-> Logistic
TISSUE-> LDA or QDA

>Q use cross validation to examine how accurate are the predictions you can make 

>Q Apply QDA to the TCGA datset for making prediction on tissues samples

>Q submit your  best predictions as a TEAM using a rds format 
